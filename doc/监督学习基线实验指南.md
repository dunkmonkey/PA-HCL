# PA-HCL 监督学习基线实验指南

## 概述

本指南介绍如何使用监督学习基线实验来验证编码器架构的有效性，并与预训练+微调的方法进行对比。

## 目的

监督学习基线实验有以下用途：

1. **验证编码器设计**: 评估编码器架构（CNN-only, CNN-Transformer, CNN-Mamba）在监督学习任务上的性能
2. **对比基线**: 作为预训练方法的对比基线，量化自监督预训练带来的增益
3. **快速原型**: 在开发新架构时快速验证想法，无需先进行预训练

## 快速开始

### 方法 1: 使用快速启动脚本（推荐）

```bash
# 在 PhysioNet 2016 数据集上运行快速测试（5 epochs）
bash scripts/run_supervised_baseline.sh physionet2016 5

# 完整训练（100 epochs）
bash scripts/run_supervised_baseline.sh physionet2016 100
```

此脚本会自动：
- 检查环境和数据
- 依次训练 CNN-only, CNN-Transformer, CNN-Mamba 三种架构
- 生成结果对比

### 方法 2: 手动运行单个实验

```bash
# 训练 CNN-Mamba 编码器
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_mamba \
    --experiment-name physionet2016_cnn_mamba

# 训练 CNN-only 编码器
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_only \
    --experiment-name physionet2016_cnn_only

# 训练 CNN-Transformer 编码器
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_transformer \
    --experiment-name physionet2016_cnn_transformer
```

## 数据准备

在运行实验前，确保已准备好下游任务数据：

```bash
# 准备 PhysioNet 2016 数据
python scripts/data_preparation/prepare_downstream_tasks.py --dataset physionet2016

# 准备其他数据集
python scripts/data_preparation/prepare_downstream_tasks.py --dataset circor_murmur
python scripts/data_preparation/prepare_downstream_tasks.py --dataset circor_outcome
python scripts/data_preparation/prepare_downstream_tasks.py --dataset pascal
```

数据应组织如下：
```
/root/autodl-tmp/data/downstream/
├── physionet2016/
│   ├── train.csv
│   ├── val.csv
│   └── test.csv
├── circor_murmur/
│   └── ...
└── ...
```

## 配置说明

主配置文件: `configs/supervised_baseline.yaml`

### 关键配置项

```yaml
# 模型架构
model:
  encoder_type: "cnn_mamba"  # 选项: cnn_only, cnn_transformer, cnn_mamba
  
  # CNN 配置（所有架构共用）
  cnn_channels: [32, 64, 128, 256]
  cnn_kernel_sizes: [7, 5, 5, 3]
  cnn_strides: [2, 2, 2, 2]
  
  # Mamba 配置（encoder_type="cnn_mamba" 时使用）
  mamba_d_model: 256
  mamba_n_layers: 4
  
  # Transformer 配置（encoder_type="cnn_transformer" 时使用）
  transformer_n_layers: 4
  transformer_n_heads: 8

# 训练配置
training:
  num_epochs: 100
  batch_size: 32
  learning_rate: 1e-3
  warmup_epochs: 10
  early_stopping_patience: 20
```

### 命令行覆盖

```bash
# 修改训练轮数
python scripts/train_supervised_baseline.py --task physionet2016 --epochs 50

# 修改学习率
python scripts/train_supervised_baseline.py --task physionet2016 --lr 5e-4

# 修改批大小
python scripts/train_supervised_baseline.py --task physionet2016 --batch-size 64

# 组合多个参数
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_mamba \
    --epochs 100 \
    --lr 1e-3 \
    --batch-size 32
```

## 实验监控

### TensorBoard

默认启用 TensorBoard 记录：

```bash
# 启动 TensorBoard
tensorboard --logdir=outputs/supervised_baseline

# 在浏览器中访问
# http://localhost:6006
```

### Weights & Biases

启用 WandB 云端跟踪：

```bash
# 首次使用需要登录
wandb login

# 启用 WandB
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --wandb \
    --wandb-project PA-HCL-Baselines
```

## 输出结果

每个实验会生成以下文件：

```
outputs/supervised_baseline/
└── physionet2016_cnn_mamba/
    ├── config.yaml              # 保存的配置
    ├── train.log                # 训练日志
    ├── results.json             # 最终结果
    ├── best_model.pt            # 最佳模型
    ├── latest_model.pt          # 最新模型
    ├── checkpoints/             # 定期检查点
    │   ├── epoch_10.pt
    │   ├── epoch_20.pt
    │   └── ...
    └── tensorboard/             # TensorBoard 日志
        └── events.out.tfevents.*
```

### results.json 示例

```json
{
  "task": "physionet2016",
  "encoder_type": "cnn_mamba",
  "experiment_name": "physionet2016_cnn_mamba",
  "seed": 42,
  "best_metrics": {
    "accuracy": 0.8523,
    "auroc": 0.9134,
    "auprc": 0.8976,
    "f1": 0.8412,
    "f1_macro": 0.8398,
    "precision": 0.8567,
    "recall": 0.8265,
    "specificity": 0.8789
  }
}
```

## 对比实验

### 1. 不同编码器架构对比

```bash
# 运行所有架构
for encoder in cnn_only cnn_transformer cnn_mamba; do
    python scripts/train_supervised_baseline.py \
        --task physionet2016 \
        --encoder-type $encoder \
        --experiment-name physionet2016_${encoder}
done

# 对比结果
python scripts/compare_results.py \
    --dir outputs/supervised_baseline \
    --pattern "physionet2016_*" \
    --metric auroc
```

### 2. 监督基线 vs 预训练+微调

```bash
# 步骤 1: 训练监督基线
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_mamba \
    --experiment-name supervised_baseline

# 步骤 2: 预训练+微调
python scripts/finetune.py \
    --task physionet2016 \
    --pretrained checkpoints/pretrain/best_model.pt \
    --experiment-name pretrained_finetuned

# 步骤 3: 对比结果
# 查看 supervised_baseline 的结果
cat outputs/supervised_baseline/supervised_baseline/results.json

# 查看 pretrained_finetuned 的结果
cat outputs/pretrained_finetuned/results.json
```

预期对比结果示例：

| 方法 | AUROC | F1-Macro | 准确率 |
|------|-------|----------|--------|
| 监督基线（CNN-Mamba） | 0.913 | 0.840 | 0.852 |
| 预训练+微调（CNN-Mamba） | 0.947 | 0.891 | 0.896 |
| **增益** | **+0.034** | **+0.051** | **+0.044** |

### 3. 不同数据集对比

```bash
# 在多个数据集上评估
for task in physionet2016 circor_murmur circor_outcome pascal; do
    python scripts/train_supervised_baseline.py \
        --task $task \
        --encoder-type cnn_mamba \
        --experiment-name ${task}_cnn_mamba
done
```

## 测试验证

运行单元测试确保一切正常：

```bash
# 运行所有测试
pytest tests/test_supervised_baseline.py -v

# 运行特定测试
pytest tests/test_supervised_baseline.py::TestSupervisedBaseline::test_model_creation -v

# 快速验证训练（仅 1 epoch）
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --epochs 1 \
    --experiment-name quick_test
```

## 常见问题

### Q1: 训练很慢怎么办？

**A:** 尝试以下优化：
- 减小批大小：`--batch-size 16`
- 减少训练轮数：`--epochs 50`
- 使用更简单的编码器：`--encoder-type cnn_only`
- 确保启用混合精度训练（默认启用）

### Q2: 内存不足（OOM）怎么办？

**A:** 
- 减小批大小：`--batch-size 16`
- 减少编码器层数（修改配置文件）
- 禁用混合精度：在配置中设置 `use_amp: false`

### Q3: 如何选择最佳编码器？

**A:** 
1. 首先运行快速实验（5-10 epochs）对比不同架构
2. 查看验证集 AUROC 和 F1 分数
3. 考虑参数量和推理速度
4. 对最佳架构进行完整训练（100 epochs）

### Q4: 监督基线和预训练+微调性能差异多大？

**A:** 
根据我们的实验：
- 在大数据集（>10k 样本）上，预训练增益约 3-5% AUROC
- 在小数据集（<1k 样本）上，预训练增益可达 10-15% AUROC
- 预训练对于泛化能力提升更明显

### Q5: 为什么监督基线很重要？

**A:** 
1. **验证架构有效性**: 确保编码器本身设计合理
2. **量化预训练增益**: 明确自监督学习带来的实际提升
3. **快速原型验证**: 测试新想法时无需先预训练
4. **公平对比**: 与其他方法对比时提供一致的基线

## 最佳实践

### 1. 实验管理

```bash
# 使用有意义的实验名称
python scripts/train_supervised_baseline.py \
    --task physionet2016 \
    --encoder-type cnn_mamba \
    --experiment-name "physionet_mamba_lr1e3_bs32_$(date +%Y%m%d)"
```

### 2. 超参数搜索

```bash
# 学习率搜索
for lr in 5e-4 1e-3 2e-3; do
    python scripts/train_supervised_baseline.py \
        --task physionet2016 \
        --lr $lr \
        --experiment-name "physionet_lr${lr}"
done
```

### 3. 多次运行取平均

```bash
# 运行多个随机种子
for seed in 42 123 456; do
    python scripts/train_supervised_baseline.py \
        --task physionet2016 \
        --seed $seed \
        --experiment-name "physionet_seed${seed}"
done
```

### 4. 保存重要结果

```bash
# 备份最佳模型
cp outputs/supervised_baseline/best_model.pt \
   checkpoints/supervised_baselines/physionet_cnn_mamba_best.pt
```

## 下一步

完成监督基线实验后，你可以：

1. **预训练模型**: 使用 `scripts/pretrain.py` 进行自监督预训练
2. **微调对比**: 使用 `scripts/finetune.py` 评估预训练增益
3. **消融实验**: 使用 `scripts/ablation.py` 分析各组件贡献
4. **发布结果**: 整理实验结果撰写论文

## 参考

- [项目使用文档](项目使用文档.md)
- [下游任务微调指南](下游任务微调使用指南.md)
- [实验监控实现总结](实验监控实现总结.md)
