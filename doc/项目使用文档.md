# PA-HCL é¡¹ç›®ä½¿ç”¨æ–‡æ¡£

æœ¬æ–‡æ¡£æä¾› PA-HCL é¡¹ç›®çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—ï¼ŒåŒ…æ‹¬ç¯å¢ƒæ­å»ºã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²ã€‚

---

## ç›®å½•

1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [é…ç½®æ–‡ä»¶è¯´æ˜](#é…ç½®æ–‡ä»¶è¯´æ˜)
4. [é¢„è®­ç»ƒ](#é¢„è®­ç»ƒ)
5. [ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ](#ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ)
6. [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
7. [æ¶ˆèå®éªŒ](#æ¶ˆèå®éªŒ)
8. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
9. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (æ¨è Ubuntu 20.04+) / macOS / Windows (WSL2)
- **Python**ï¼š3.10+
- **GPU**ï¼šNVIDIA GPU with CUDA 11.8+ (æ¨è)
- **å†…å­˜**ï¼šè‡³å°‘ 16GB RAM
- **å­˜å‚¨**ï¼šè‡³å°‘ 50GB å¯ç”¨ç©ºé—´

### æ­¥éª¤ 1: å…‹éš†ä»“åº“

```bash
git clone https://github.com/dunkmonkey/PA-HCL.git
cd PA-HCL
```

### æ­¥éª¤ 2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

#### ä½¿ç”¨ Condaï¼ˆæ¨èï¼‰

```bash
# åˆ›å»ºæ–°ç¯å¢ƒ
conda create -n pahcl python=3.10
conda activate pahcl
```

#### ä½¿ç”¨ venv

```bash
python3.10 -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ–
.\venv\Scripts\activate  # Windows
```

### æ­¥éª¤ 3: å®‰è£… PyTorch

æ ¹æ®æ‚¨çš„ CUDA ç‰ˆæœ¬å®‰è£… PyTorchï¼š

```bash
# CUDA 11.8
pip install torch==2.1.2 torchaudio==2.1.2 torchvision==0.16.2 \
    --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch==2.1.2 torchaudio==2.1.2 torchvision==0.16.2 \
    --index-url https://download.pytorch.org/whl/cu121

# CPU only (ä¸æ¨èç”¨äºè®­ç»ƒ)
pip install torch==2.1.2 torchaudio==2.1.2 torchvision==0.16.2 \
    --index-url https://download.pytorch.org/whl/cpu
```

### æ­¥éª¤ 4: å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# ä»¥å¼€å‘æ¨¡å¼å®‰è£…é¡¹ç›®
pip install -e .
```

### æ­¥éª¤ 5: éªŒè¯å®‰è£…

```bash
# æµ‹è¯• PyTorch æ˜¯å¦æ­£ç¡®å®‰è£…
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"

# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/ -v
```

**é¢„æœŸè¾“å‡º**ï¼š
```
PyTorch: 2.1.2
CUDA available: True
```

---

## æ•°æ®å‡†å¤‡

### æ•°æ®ç»„ç»‡ç»“æ„

PA-HCL è¦æ±‚åŸå§‹æ•°æ®æŒ‰**å—è¯•è€…**ç»„ç»‡ï¼ˆsubject-wiseï¼‰ï¼Œä»¥ç¡®ä¿è®­ç»ƒ/æµ‹è¯•æ•°æ®åˆ’åˆ†ä¸æ³„éœ²ï¼š

```
/root/autodl-tmp/data/raw/
â”œâ”€â”€ subject_0001/
â”‚   â”œâ”€â”€ rec_01.wav
â”‚   â”œâ”€â”€ rec_02.wav
â”‚   â””â”€â”€ rec_03.wav
â”œâ”€â”€ subject_0002/
â”‚   â”œâ”€â”€ rec_01.wav
â”‚   â””â”€â”€ rec_02.wav
â”œâ”€â”€ subject_0003/
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### æ•°æ®æ ¼å¼è¦æ±‚

- **æ–‡ä»¶æ ¼å¼**ï¼š`.wav` (16-bit PCM æˆ–æµ®ç‚¹)
- **é‡‡æ ·ç‡**ï¼šåŸå§‹é‡‡æ ·ç‡ä¸é™ï¼Œä¼šè‡ªåŠ¨é‡é‡‡æ ·åˆ°é…ç½®çš„é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 5000 Hzï¼‰
- **é€šé“æ•°**ï¼šå•å£°é“æˆ–ç«‹ä½“å£°ï¼ˆç«‹ä½“å£°ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå•å£°é“ï¼‰
- **æ—¶é•¿**ï¼šæ¯ä¸ªå½•éŸ³è‡³å°‘åŒ…å« 2-3 ä¸ªå®Œæ•´å¿ƒåŠ¨å‘¨æœŸ

### æ­¥éª¤ 1: å‡†å¤‡åŸå§‹æ•°æ®

å°†æ‚¨çš„å¿ƒéŸ³æ•°æ®æŒ‰ä¸Šè¿°ç»“æ„æ”¾ç½®åˆ° `/root/autodl-tmp/data/raw/` ç›®å½•ã€‚

**ç¤ºä¾‹æ•°æ®é›†**ï¼š
- CirCor DigiScope Dataset
- PhysioNet 2016 Challenge Dataset
- Pascal Challenge Dataset

### æ­¥éª¤ 2: è¿è¡Œé¢„å¤„ç†

```bash
python scripts/preprocess.py --config configs/default.yaml
```

**é¢„å¤„ç†æµç¨‹**ï¼š
1. åŠ è½½æ¯ä¸ª `.wav` æ–‡ä»¶
2. é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 5000 Hzï¼‰
3. å¸¦é€šæ»¤æ³¢ï¼ˆ25-400 Hzï¼Œå»é™¤å™ªå£°ï¼‰
4. æ£€æµ‹å¿ƒåŠ¨å‘¨æœŸï¼ˆåŸºäºèƒ½é‡åŒ…ç»œï¼‰
5. åˆ‡åˆ†å¹¶ä¿å­˜æ¯ä¸ªå¿ƒåŠ¨å‘¨æœŸä¸ºç‹¬ç«‹æ–‡ä»¶

**è¾“å‡ºç»“æ„**ï¼š
```
/root/autodl-tmp/data/processed/
â”œâ”€â”€ subject_0001/
â”‚   â”œâ”€â”€ rec_01/
â”‚   â”‚   â”œâ”€â”€ cycle_000.npy
â”‚   â”‚   â”œâ”€â”€ cycle_001.npy
â”‚   â”‚   â”œâ”€â”€ cycle_002.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ rec_02/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ subject_0002/
â”‚   â””â”€â”€ ...
â””â”€â”€ statistics.json  # æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
```

### æ­¥éª¤ 3: éªŒè¯é¢„å¤„ç†ç»“æœ

```bash
# æ£€æŸ¥å¤„ç†åçš„æ•°æ®
python -c "
from pathlib import Path
import numpy as np

processed_dir = Path('/root/autodl-tmp/data/processed')
cycle_files = list(processed_dir.rglob('*.npy'))
print(f'Total cycles: {len(cycle_files)}')

# æ£€æŸ¥ç¬¬ä¸€ä¸ªå‘¨æœŸ
if cycle_files:
    cycle = np.load(cycle_files[0])
    print(f'Cycle shape: {cycle.shape}')
    print(f'Cycle dtype: {cycle.dtype}')
    print(f'Cycle range: [{cycle.min():.3f}, {cycle.max():.3f}]')
"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
Total cycles: 15234
Cycle shape: (4000,)
Cycle dtype: float32
Cycle range: [-0.982, 0.945]
```

---

## é…ç½®æ–‡ä»¶è¯´æ˜

PA-HCL ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶ç®¡ç†æ‰€æœ‰è¶…å‚æ•°ã€‚ä¸»è¦é…ç½®æ–‡ä»¶ï¼š

### `configs/default.yaml` - é»˜è®¤é…ç½®

åŒ…å«æ‰€æœ‰å¯é…ç½®å‚æ•°çš„é»˜è®¤å€¼ã€‚

**å…³é”®å‚æ•°**ï¼š

```yaml
# æ•°æ®é…ç½®
data:
  raw_dir: "./data/raw"              # åŸå§‹æ•°æ®ç›®å½•
  processed_dir: "./data/processed"  # å¤„ç†åæ•°æ®ç›®å½•
  sample_rate: 5000                  # é‡‡æ ·ç‡ (Hz)
  num_substructures: 4               # å­ç»“æ„æ•°é‡ K
  
  cycle:
    min_duration: 0.4                # æœ€å°å¿ƒåŠ¨å‘¨æœŸæ—¶é•¿ (ç§’)
    max_duration: 1.5                # æœ€å¤§å¿ƒåŠ¨å‘¨æœŸæ—¶é•¿ (ç§’)
    target_length: 4000              # ç›®æ ‡é•¿åº¦ (é‡‡æ ·ç‚¹æ•°)

# æ¨¡å‹é…ç½®
model:
  encoder:
    type: "cnn_mamba"                # ç¼–ç å™¨ç±»å‹
    cnn:
      channels: [32, 64, 128, 256]   # CNN é€šé“æ•°
      kernel_sizes: [7, 5, 5, 3]     # å·ç§¯æ ¸å¤§å°
      strides: [2, 2, 2, 2]          # ä¸‹é‡‡æ ·æ­¥å¹…
    mamba:
      d_model: 256                   # Mamba éšè—ç»´åº¦
      n_layers: 4                    # Mamba å±‚æ•°
      d_state: 16                    # çŠ¶æ€ç»´åº¦

# æŸå¤±é…ç½®
loss:
  temperature: 0.07                  # InfoNCE æ¸©åº¦
  lambda_cycle: 1.0                  # å‘¨æœŸçº§æŸå¤±æƒé‡
  lambda_sub: 1.0                    # å­ç»“æ„çº§æŸå¤±æƒé‡

# è®­ç»ƒé…ç½®
training:
  pretrain:
    epochs: 100                      # è®­ç»ƒè½®æ•°
    batch_size: 64                   # æ‰¹æ¬¡å¤§å°
    optimizer:
      lr: 1.0e-3                     # å­¦ä¹ ç‡
      weight_decay: 1.0e-4           # æƒé‡è¡°å‡
```

### `configs/pretrain.yaml` - é¢„è®­ç»ƒé…ç½®

ä¸“é—¨ç”¨äºè‡ªç›‘ç£é¢„è®­ç»ƒçš„é…ç½®ï¼Œç»§æ‰¿è‡ª `default.yaml`ã€‚

### `configs/finetune.yaml` - å¾®è°ƒé…ç½®

ç”¨äºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒçš„é…ç½®ã€‚

```yaml
training:
  finetune:
    epochs: 50
    batch_size: 32
    encoder_lr: 1.0e-4               # ç¼–ç å™¨å­¦ä¹ ç‡ï¼ˆè¾ƒå°ï¼‰
    head_lr: 1.0e-3                  # åˆ†ç±»å¤´å­¦ä¹ ç‡ï¼ˆè¾ƒå¤§ï¼‰
    freeze_encoder: false            # æ˜¯å¦å†»ç»“ç¼–ç å™¨
```

### `configs/ablation.yaml` - æ¶ˆèå®éªŒé…ç½®

ç”¨äºæ¶ˆèå®éªŒçš„é…ç½®ã€‚

### ä¿®æ”¹é…ç½®

æœ‰ä¸‰ç§æ–¹å¼ä¿®æ”¹é…ç½®ï¼š

#### æ–¹æ³• 1: ç›´æ¥ç¼–è¾‘ YAML æ–‡ä»¶

```bash
vim configs/pretrain.yaml
```

#### æ–¹æ³• 2: å‘½ä»¤è¡Œè¦†ç›–

```bash
python scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --batch-size 128 \
    --learning-rate 2e-3
```

#### æ–¹æ³• 3: åˆ›å»ºè‡ªå®šä¹‰é…ç½®

```bash
cp configs/pretrain.yaml configs/my_config.yaml
vim configs/my_config.yaml
python scripts/pretrain.py --config configs/my_config.yaml
```

---

## é¢„è®­ç»ƒ

é¢„è®­ç»ƒæ˜¯ PA-HCL çš„æ ¸å¿ƒæ­¥éª¤ï¼Œä»å¤§é‡æ— æ ‡æ³¨å¿ƒéŸ³æ•°æ®ä¸­å­¦ä¹ é€šç”¨è¡¨ç¤ºã€‚

### å• GPU è®­ç»ƒ

```bash
python scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --experiment-name my_pretrain \
    --output-dir outputs
```

### å¤š GPU è®­ç»ƒï¼ˆåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼‰

```bash
# ä½¿ç”¨ 4 ä¸ª GPU
torchrun --nproc_per_node=4 scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --distributed \
    --experiment-name my_pretrain_ddp
```

### ä½¿ç”¨ Weights & Biases è®°å½•

```bash
python scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --use-wandb \
    --wandb-project PA-HCL \
    --experiment-name my_pretrain_wandb
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤

```bash
python scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --resume outputs/my_pretrain/epoch_50.pt
```

### é¢„è®­ç»ƒè¾“å‡º

```
outputs/
â””â”€â”€ my_pretrain/
    â”œâ”€â”€ config.yaml              # ä¿å­˜çš„é…ç½®
    â”œâ”€â”€ train.log                # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ epoch_10.pt              # æ¯ 10 è½®ä¿å­˜çš„æ£€æŸ¥ç‚¹
    â”œâ”€â”€ epoch_20.pt
    â”œâ”€â”€ ...
    â”œâ”€â”€ last_model.pt            # æœ€åä¸€è½®çš„æ¨¡å‹
    â””â”€â”€ best_model.pt            # éªŒè¯é›†ä¸Šæœ€ä½³æ¨¡å‹ï¼ˆå¦‚æœ‰éªŒè¯é›†ï¼‰
```

### ç›‘æ§è®­ç»ƒ

#### ä½¿ç”¨ W&B

Weights & Biases æä¾›æ›´å¼ºå¤§çš„å®éªŒè·Ÿè¸ªã€å¯è§†åŒ–å’Œåä½œåŠŸèƒ½ã€‚

**æ­¥éª¤ 1ï¼šå®‰è£…å’Œç™»å½•**

```bash
# å®‰è£… wandb
pip install wandb

# ç™»å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
wandb login
```

è®¿é—® https://wandb.ai/authorize è·å– API keyã€‚

**æ­¥éª¤ 2ï¼šå¯ç”¨ W&B è®°å½•**

åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ  W&B ç›¸å…³å‚æ•°ï¼š

```bash
# é¢„è®­ç»ƒ
python scripts/pretrain.py \
    --config configs/pretrain.yaml \
    --use-wandb \
    --wandb-project PA-HCL \
    --wandb-entity your-team \
    --experiment-name my_pretrain_wandb

# å¾®è°ƒ
python scripts/finetune.py \
    --config configs/finetune.yaml \
    --pretrained outputs/pretrain/best_model.pt \
    --use-wandb \
    --wandb-project PA-HCL-Finetune \
    --experiment-name downstream_task
```

**å‚æ•°è¯´æ˜**ï¼š
- `--use-wandb`ï¼šå¯ç”¨ W&B è®°å½•
- `--wandb-project`ï¼šé¡¹ç›®åç§°ï¼ˆç”¨äºç»„ç»‡å®éªŒï¼‰
- `--wandb-entity`ï¼šå›¢é˜Ÿ/ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰
- `--experiment-name`ï¼šè¿è¡Œåç§°

**æ­¥éª¤ 3ï¼šæŸ¥çœ‹ W&B é¢æ¿**

è®­ç»ƒå¼€å§‹åï¼Œç»ˆç«¯ä¼šæ˜¾ç¤ºé¢æ¿é“¾æ¥ï¼š
```
wandb: ğŸš€ View run at https://wandb.ai/your-username/PA-HCL/runs/xxxxx
```

è®¿é—®é“¾æ¥æŸ¥çœ‹ï¼š
- å®æ—¶è®­ç»ƒæ›²çº¿
- ç³»ç»Ÿèµ„æºç›‘æ§ï¼ˆGPUã€CPUã€å†…å­˜ï¼‰
- è¶…å‚æ•°é…ç½®
- æ¨¡å‹æ¶æ„
- æ—¥å¿—è¾“å‡º

**W&B é«˜çº§ç”¨æ³•**ï¼š

1. **æ·»åŠ æ ‡ç­¾å’Œåˆ†ç»„**ï¼š
   ```bash
   python scripts/pretrain.py \
       --config configs/pretrain.yaml \
       --use-wandb \
       --wandb-project PA-HCL \
       --experiment-name encoder_cnn_mamba \
       --wandb-tags "ablation,encoder,mamba" \
       --wandb-group "encoder_comparison"
   ```

2. **ç¦»çº¿æ¨¡å¼**ï¼ˆç½‘ç»œå—é™æ—¶ï¼‰ï¼š
   ```bash
   export WANDB_MODE=offline
   python scripts/pretrain.py --use-wandb ...
   
   # è®­ç»ƒå®ŒæˆååŒæ­¥
   wandb sync outputs/my_pretrain/wandb
   ```

3. **æ¢å¤è¿è¡Œ**ï¼š
   ```bash
   python scripts/pretrain.py \
       --resume outputs/my_pretrain/epoch_50.pt \
       --wandb-resume-id xxxxx  # ä» W&B é¢æ¿è·å– run ID
   ```

**ç›‘æ§çš„å…³é”®æŒ‡æ ‡**ï¼š

é¢„è®­ç»ƒé˜¶æ®µï¼š
- `cycle_loss`ï¼šå‘¨æœŸçº§å¯¹æ¯”æŸå¤±ï¼ˆåº”é€æ¸ä¸‹é™ï¼‰
- `sub_loss`ï¼šå­ç»“æ„çº§å¯¹æ¯”æŸå¤±ï¼ˆåº”é€æ¸ä¸‹é™ï¼‰
- `total_loss`ï¼šæ€»æŸå¤± = Î»_cycle Ã— cycle_loss + Î»_sub Ã— sub_loss
- `learning_rate`ï¼šå­¦ä¹ ç‡å˜åŒ–ï¼ˆwarmup + cosine decayï¼‰
- `grad_norm`ï¼šæ¢¯åº¦èŒƒæ•°ï¼ˆè¿‡å¤§è¡¨ç¤ºæ¢¯åº¦çˆ†ç‚¸ï¼‰

å¾®è°ƒé˜¶æ®µï¼š
- `train_loss` / `val_loss`ï¼šè®­ç»ƒ/éªŒè¯æŸå¤±
- `train_acc` / `val_acc`ï¼šè®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡
- `auroc`ï¼šROC æ›²çº¿ä¸‹é¢ç§¯
- `auprc`ï¼šPR æ›²çº¿ä¸‹é¢ç§¯
- `f1_score`ï¼šF1 åˆ†æ•°

**æ•…éšœæ’æŸ¥**ï¼š

1. **TensorBoard æ— æ³•è®¿é—®**ï¼š
   ```bash
   # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
   pip install tensorboard
   
   # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
   tensorboard --logdir outputs --port 6007
   ```

2. **W&B ç™»å½•å¤±è´¥**ï¼š
   ```bash
   # é‡æ–°ç™»å½•
   wandb login --relogin
   
   # æˆ–ç›´æ¥ä½¿ç”¨ API key
   wandb login --relogin YOUR_API_KEY
   ```

3. **W&B åŒæ­¥æ…¢**ï¼š
   ```bash
   # å‡å°‘æ—¥å¿—é¢‘ç‡ï¼ˆåœ¨é…ç½®æ–‡ä»¶ä¸­ï¼‰
   training:
     log_interval: 100  # æ¯ 100 æ­¥è®°å½•ä¸€æ¬¡ï¼ˆé»˜è®¤ 10ï¼‰
   ```

### é¢„è®­ç»ƒæœ€ä½³å®è·µ

1. **æ‰¹æ¬¡å¤§å°**ï¼š
   - å• GPUï¼š64-128ï¼ˆå–å†³äº GPU å†…å­˜ï¼‰
   - å¤š GPUï¼šæ¯ä¸ª GPU 64ï¼Œæ€» effective batch size = 64 Ã— N_GPU

2. **å­¦ä¹ ç‡**ï¼š
   - åŸºå‡†ï¼š1e-3
   - ä½¿ç”¨å¤§æ‰¹æ¬¡æ—¶ï¼šlr = base_lr Ã— sqrt(batch_size / 64)
   - ç¤ºä¾‹ï¼šbatch_size=256 â†’ lr=2e-3

3. **è®­ç»ƒæ—¶é•¿**ï¼š
   - å°æ•°æ®é›†ï¼ˆ<10k æ ·æœ¬ï¼‰ï¼š50-100 epochs
   - å¤§æ•°æ®é›†ï¼ˆ>100k æ ·æœ¬ï¼‰ï¼š100-200 epochs
   - è§‚å¯ŸéªŒè¯é›†æŸå¤±ï¼Œå‡ºç°è¿‡æ‹Ÿåˆæ—¶æå‰åœæ­¢

4. **æ··åˆç²¾åº¦**ï¼š
   - æ¨èå¼€å¯ï¼ˆ`use_amp: true`ï¼‰ï¼Œå¯èŠ‚çœçº¦ 50% å†…å­˜
   - æŸäº›ç¡¬ä»¶ï¼ˆV100, A100ï¼‰å¯è·å¾— 2-3x åŠ é€Ÿ

---

## ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ

é¢„è®­ç»ƒå®Œæˆåï¼Œåœ¨ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡ä¸Šå¾®è°ƒæ¨¡å‹ã€‚

### ä»»åŠ¡ç±»å‹

#### 1. çº¿æ€§è¯„ä¼°ï¼ˆLinear Evaluationï¼‰

**ç‰¹ç‚¹**ï¼šå†»ç»“ç¼–ç å™¨ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´

**ç”¨é€”**ï¼šè¯„ä¼°é¢„è®­ç»ƒè¡¨ç¤ºçš„è´¨é‡

```bash
python scripts/finetune.py \
    --config configs/finetune.yaml \
    --pretrained outputs/my_pretrain/best_model.pt \
    --linear-eval \
    --num-classes 2 \
    --experiment-name linear_eval
```

#### 2. å…¨é‡å¾®è°ƒï¼ˆFull Fine-tuningï¼‰

**ç‰¹ç‚¹**ï¼šç¼–ç å™¨å’Œåˆ†ç±»å¤´éƒ½å‚ä¸è®­ç»ƒ

**ç”¨é€”**ï¼šè¿½æ±‚æœ€ä½³æ€§èƒ½

```bash
python scripts/finetune.py \
    --config configs/finetune.yaml \
    --pretrained outputs/my_pretrain/best_model.pt \
    --num-classes 2 \
    --experiment-name full_finetune
```

#### 3. å°æ ·æœ¬å­¦ä¹ ï¼ˆFew-shot Learningï¼‰

**ç‰¹ç‚¹**ï¼šä»…ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®

**ç”¨é€”**ï¼šè¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹çš„æ•°æ®æ•ˆç‡

```bash
# ä½¿ç”¨ 10% è®­ç»ƒæ•°æ®
python scripts/finetune.py \
    --config configs/finetune.yaml \
    --pretrained outputs/my_pretrain/best_model.pt \
    --few-shot \
    --shot-ratio 0.1 \
    --num-classes 2 \
    --experiment-name few_shot_10pct

# ä½¿ç”¨ 1% è®­ç»ƒæ•°æ®
python scripts/finetune.py \
    --config configs/finetune.yaml \
    --pretrained outputs/my_pretrain/best_model.pt \
    --few-shot \
    --shot-ratio 0.01 \
    --num-classes 2 \
    --experiment-name few_shot_1pct
```

### å‡†å¤‡ä¸‹æ¸¸æ•°æ®

ä¸‹æ¸¸ä»»åŠ¡éœ€è¦å¸¦æ ‡ç­¾çš„æ•°æ®ï¼š

```
data/downstream/
â”œâ”€â”€ train.csv
â”œâ”€â”€ val.csv
â””â”€â”€ test.csv
```

**CSV æ ¼å¼**ï¼š
```csv
file_path,label
data/raw/subject_0001/rec_01.wav,0
data/raw/subject_0001/rec_02.wav,1
data/raw/subject_0002/rec_01.wav,0
...
```

### å¾®è°ƒé…ç½®

**å…³é”®å‚æ•°**ï¼š

```yaml
# configs/finetune.yaml
data:
  train_csv: "data/downstream/train.csv"
  val_csv: "data/downstream/val.csv"
  test_csv: "data/downstream/test.csv"
  num_classes: 2                    # åˆ†ç±»ç±»åˆ«æ•°

training:
  finetune:
    epochs: 50
    batch_size: 32
    encoder_lr: 1.0e-4              # ç¼–ç å™¨å­¦ä¹ ç‡ï¼ˆå°ï¼‰
    head_lr: 1.0e-3                 # åˆ†ç±»å¤´å­¦ä¹ ç‡ï¼ˆå¤§ï¼‰
    freeze_encoder: false           # çº¿æ€§è¯„ä¼°æ—¶è®¾ä¸º true
    
    # æ—©åœ
    early_stopping:
      patience: 10                  # éªŒè¯é›†æ— æ”¹å–„æ—¶çš„ç­‰å¾…è½®æ•°
      min_delta: 0.001              # æœ€å°æ”¹å–„å¹…åº¦
```

### å¾®è°ƒè¾“å‡º

```
outputs/
â””â”€â”€ full_finetune/
    â”œâ”€â”€ config.yaml
    â”œâ”€â”€ train.log
    â”œâ”€â”€ best_model.pt               # éªŒè¯é›†ä¸Šæœ€ä½³æ¨¡å‹
    â”œâ”€â”€ last_model.pt
    â”œâ”€â”€ confusion_matrix.png        # æ··æ·†çŸ©é˜µ
    â””â”€â”€ metrics.json                # è¯„ä¼°æŒ‡æ ‡
```

---

## æ¨¡å‹è¯„ä¼°

### è¯„ä¼°æŒ‡æ ‡

PA-HCL æ”¯æŒä»¥ä¸‹è¯„ä¼°æŒ‡æ ‡ï¼š

- **å‡†ç¡®ç‡ (Accuracy)**ï¼šæ•´ä½“åˆ†ç±»æ­£ç¡®ç‡
- **AUROC (Area Under ROC)**ï¼šROC æ›²çº¿ä¸‹é¢ç§¯
- **AUPRC (Area Under Precision-Recall)**ï¼šPR æ›²çº¿ä¸‹é¢ç§¯
- **F1-score**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **Precision**ï¼šç²¾ç¡®ç‡
- **Recall**ï¼šå¬å›ç‡
- **Specificity**ï¼šç‰¹å¼‚æ€§

### è¿è¡Œè¯„ä¼°

```bash
python scripts/evaluate.py \
    --checkpoint outputs/full_finetune/best_model.pt \
    --data-csv data/downstream/test.csv \
    --config configs/finetune.yaml \
    --output-dir outputs/evaluation \
    --confusion-matrix \
    --roc-curve \
    --pr-curve
```

### è¯„ä¼°è¾“å‡º

```
outputs/evaluation/
â”œâ”€â”€ metrics.json                 # æ‰€æœ‰æŒ‡æ ‡çš„ JSON æ–‡ä»¶
â”œâ”€â”€ confusion_matrix.png         # æ··æ·†çŸ©é˜µå¯è§†åŒ–
â”œâ”€â”€ roc_curve.png                # ROC æ›²çº¿
â”œâ”€â”€ pr_curve.png                 # Precision-Recall æ›²çº¿
â””â”€â”€ predictions.csv              # æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
```

**metrics.json ç¤ºä¾‹**ï¼š
```json
{
  "accuracy": 0.8523,
  "auroc": 0.9234,
  "auprc": 0.8967,
  "f1_score": 0.8421,
  "precision": 0.8654,
  "recall": 0.8198,
  "specificity": 0.8734,
  "confusion_matrix": [[456, 67], [89, 388]]
}
```

### æ‰¹é‡è¯„ä¼°

è¯„ä¼°å¤šä¸ªæ£€æŸ¥ç‚¹ï¼š

```bash
# è¯„ä¼°è„šæœ¬
for ckpt in outputs/full_finetune/epoch_*.pt; do
    echo "Evaluating $ckpt"
    python scripts/evaluate.py \
        --checkpoint "$ckpt" \
        --data-csv data/downstream/test.csv \
        --output-dir "outputs/evaluation/$(basename $ckpt .pt)"
done
```

### è·¨æ•°æ®é›†è¯„ä¼°

è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼š

```bash
# åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¯„ä¼°
python scripts/evaluate.py \
    --checkpoint outputs/full_finetune/best_model.pt \
    --data-csv data/external_dataset/test.csv \
    --config configs/finetune.yaml \
    --output-dir outputs/evaluation_external
```

---

## æ¶ˆèå®éªŒ

æ¶ˆèå®éªŒç”¨äºåˆ†æä¸åŒç»„ä»¶çš„è´¡çŒ®ã€‚

### è¿è¡Œæ‰€æœ‰æ¶ˆè

```bash
python scripts/ablation.py \
    --config configs/ablation.yaml \
    --all \
    --output-dir outputs/ablation
```

### å•ç‹¬è¿è¡Œæ¶ˆè

#### 1. å±‚æ¬¡ç»“æ„æ¶ˆè

éªŒè¯å‘¨æœŸçº§å’Œå­ç»“æ„çº§å¯¹æ¯”çš„ä½œç”¨ï¼š

```bash
python scripts/ablation.py \
    --config configs/ablation.yaml \
    --hierarchy-ablation \
    --output-dir outputs/ablation/hierarchy
```

**å®éªŒé…ç½®**ï¼š
- **ä»…å‘¨æœŸçº§**ï¼š`lambda_cycle=1.0, lambda_sub=0.0`
- **ä»…å­ç»“æ„çº§**ï¼š`lambda_cycle=0.0, lambda_sub=1.0`
- **å®Œæ•´æ–¹æ³•**ï¼š`lambda_cycle=1.0, lambda_sub=1.0`

#### 2. ç¼–ç å™¨æ¶æ„æ¶ˆè

å¯¹æ¯”ä¸åŒç¼–ç å™¨çš„æ€§èƒ½ï¼š

```bash
python scripts/ablation.py \
    --config configs/ablation.yaml \
    --encoder-ablation \
    --output-dir outputs/ablation/encoder
```

**å®éªŒé…ç½®**ï¼š
- **CNN-only**ï¼š`encoder_type="cnn_only"`
- **CNN-Transformer**ï¼š`encoder_type="cnn_transformer"`
- **CNN-Mamba**ï¼š`encoder_type="cnn_mamba"`ï¼ˆæœ¬æ–‡ï¼‰

#### 3. å­ç»“æ„æ•°é‡æ¶ˆè

æ¢ç´¢æœ€ä¼˜çš„å­ç»“æ„åˆ’åˆ†ï¼š

```bash
python scripts/ablation.py \
    --config configs/ablation.yaml \
    --num-substructures-ablation \
    --output-dir outputs/ablation/num_subs
```

**å®éªŒé…ç½®**ï¼š
- **K=2**ï¼šç²—ç²’åº¦åˆ’åˆ†
- **K=4**ï¼šé»˜è®¤é…ç½®
- **K=6**ï¼šç»†ç²’åº¦åˆ’åˆ†

#### 4. æŸå¤±æƒé‡æ¶ˆè

å¯»æ‰¾æœ€ä¼˜çš„æŸå¤±æƒé‡ç»„åˆï¼š

```bash
python scripts/ablation.py \
    --config configs/ablation.yaml \
    --loss-weight-ablation \
    --output-dir outputs/ablation/loss_weights
```

**å®éªŒé…ç½®**ï¼š
- `(Î»_cycle, Î»_sub) = (1.0, 0.0), (1.0, 0.5), (1.0, 1.0), (0.5, 1.0), (0.0, 1.0)`

### æ¶ˆèå®éªŒè¾“å‡º

```
outputs/ablation/
â”œâ”€â”€ hierarchy/
â”‚   â”œâ”€â”€ cycle_only/
â”‚   â”‚   â”œâ”€â”€ pretrain/
â”‚   â”‚   â””â”€â”€ finetune/
â”‚   â”œâ”€â”€ sub_only/
â”‚   â”‚   â”œâ”€â”€ pretrain/
â”‚   â”‚   â””â”€â”€ finetune/
â”‚   â””â”€â”€ full/
â”‚       â”œâ”€â”€ pretrain/
â”‚       â””â”€â”€ finetune/
â”œâ”€â”€ encoder/
â”‚   â”œâ”€â”€ cnn_only/
â”‚   â”œâ”€â”€ cnn_transformer/
â”‚   â””â”€â”€ cnn_mamba/
â””â”€â”€ summary.csv                  # æ‰€æœ‰æ¶ˆèç»“æœæ±‡æ€»
```

**summary.csv ç¤ºä¾‹**ï¼š
```csv
experiment,encoder,lambda_cycle,lambda_sub,K,accuracy,auroc,f1
cycle_only,cnn_mamba,1.0,0.0,4,0.8234,0.8923,0.8156
sub_only,cnn_mamba,0.0,1.0,4,0.8156,0.8745,0.8067
full,cnn_mamba,1.0,1.0,4,0.8523,0.9234,0.8421
...
```

---

## å¸¸è§é—®é¢˜

### Q1: å†…å­˜ä¸è¶³ (Out of Memory)

**ç—‡çŠ¶**ï¼š`RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **å‡å°æ‰¹æ¬¡å¤§å°**ï¼š
   ```yaml
   training:
     pretrain:
       batch_size: 32  # ä» 64 å‡åˆ° 32
   ```

2. **å¯ç”¨æ··åˆç²¾åº¦**ï¼š
   ```yaml
   training:
     use_amp: true
   ```

3. **ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯**ï¼š
   ```yaml
   training:
     batch_size: 16
     gradient_accumulation_steps: 4  # effective batch_size = 16 Ã— 4 = 64
   ```

4. **å‡å°‘æ¨¡å‹å¤§å°**ï¼š
   ```yaml
   model:
     mamba:
       d_model: 128     # ä» 256 å‡åˆ° 128
       n_layers: 2      # ä» 4 å‡åˆ° 2
   ```

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **å¯ç”¨æ··åˆç²¾åº¦**ï¼ˆAMPï¼‰
2. **å¢åŠ  num_workers**ï¼š
   ```yaml
   training:
     num_workers: 8  # æ•°æ®åŠ è½½å¹¶è¡Œåº¦
   ```
3. **ä½¿ç”¨å¤š GPU**ï¼š
   ```bash
   torchrun --nproc_per_node=4 scripts/pretrain.py --distributed
   ```
4. **æ•°æ®ç¼“å­˜åˆ°å†…å­˜**ï¼š
   ```python
   dataset = PCGPretrainDataset(..., cache_in_memory=True)
   ```

### Q3: é¢„å¤„ç†åå‘¨æœŸæ•°é‡ä¸ç¬¦åˆé¢„æœŸ

**å¯èƒ½åŸå› **ï¼š
- éŸ³é¢‘è´¨é‡å·®ï¼Œä¿¡å™ªæ¯”ä½
- å¿ƒåŠ¨å‘¨æœŸæ£€æµ‹é˜ˆå€¼ä¸åˆé€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

è°ƒæ•´é¢„å¤„ç†å‚æ•°ï¼š
```yaml
data:
  cycle:
    min_duration: 0.3  # é™ä½æœ€å°æ—¶é•¿
    max_duration: 2.0  # å¢åŠ æœ€å¤§æ—¶é•¿
  filter:
    min_snr_db: 5.0    # é™ä½ SNR é˜ˆå€¼ï¼ˆä½†å¯èƒ½å¼•å…¥å™ªå£°ï¼‰
```

### Q4: æ¨¡å‹æ€§èƒ½ä¸ä½³

**è¯Šæ–­æ­¥éª¤**ï¼š

1. **æ£€æŸ¥æ•°æ®è´¨é‡**ï¼š
   ```bash
   python -c "
   import numpy as np
   from pathlib import Path
   
   cycles = [np.load(f) for f in Path('data/processed').rglob('*.npy')[:100]]
   print('Mean:', np.mean([c.mean() for c in cycles]))
   print('Std:', np.mean([c.std() for c in cycles]))
   "
   ```

2. **å¯è§†åŒ–æ ·æœ¬**ï¼š
   ```python
   import matplotlib.pyplot as plt
   import numpy as np
   
   cycle = np.load('data/processed/subject_0001/rec_01/cycle_000.npy')
   plt.plot(cycle)
   plt.title('Heart Sound Cycle')
   plt.xlabel('Sample')
   plt.ylabel('Amplitude')
   plt.savefig('cycle_visualization.png')
   ```

3. **æ£€æŸ¥è®­ç»ƒæ—¥å¿—**ï¼š
   - Loss æ˜¯å¦ä¸‹é™ï¼Ÿ
   - æ˜¯å¦å‡ºç°æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ï¼Ÿ

4. **å°è¯•ä¸åŒçš„è¶…å‚æ•°**ï¼š
   - å­¦ä¹ ç‡ï¼š1e-4, 5e-4, 1e-3, 2e-3
   - æ¸©åº¦ç³»æ•°ï¼š0.05, 0.07, 0.1
   - æŸå¤±æƒé‡ï¼šä¸åŒçš„ Î» ç»„åˆ

### Q5: Mamba å®‰è£…å¤±è´¥

**ç—‡çŠ¶**ï¼š`ERROR: Failed building wheel for mamba-ssm`

**åŸå› **ï¼šMamba éœ€è¦ CUDA å’Œç¼–è¯‘ç¯å¢ƒ

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **ç¡®ä¿å®‰è£…äº† CUDA toolkit**ï¼š
   ```bash
   nvcc --version
   ```

2. **å®‰è£…ç¼–è¯‘ä¾èµ–**ï¼š
   ```bash
   # Ubuntu
   sudo apt-get install build-essential
   
   # CentOS
   sudo yum groupinstall "Development Tools"
   ```

3. **ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬**ï¼ˆå¦‚å¯ç”¨ï¼‰ï¼š
   ```bash
   pip install mamba-ssm --find-links https://github.com/state-spaces/mamba/releases
   ```

4. **å›é€€åˆ° Transformer**ï¼š
   ```yaml
   model:
     encoder:
       type: "cnn_transformer"  # ä¸éœ€è¦ Mamba
   ```

### Q6: åˆ†å¸ƒå¼è®­ç»ƒæŠ¥é”™

**ç—‡çŠ¶**ï¼š`RuntimeError: Default process group has not been initialized`

**è§£å†³æ–¹æ¡ˆ**ï¼š

ç¡®ä¿ä½¿ç”¨ `torchrun` å¯åŠ¨ï¼š
```bash
# æ­£ç¡®
torchrun --nproc_per_node=4 scripts/pretrain.py --distributed

# é”™è¯¯
python scripts/pretrain.py --distributed  # ç¼ºå°‘ torchrun
```

### Q7: å¦‚ä½•å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **ç±»åˆ«åŠ æƒ**ï¼š
   ```python
   # åœ¨å¾®è°ƒæ—¶
   class_weights = torch.tensor([1.0, 5.0])  # æ­£å¸¸:å¼‚å¸¸ = 5:1
   criterion = nn.CrossEntropyLoss(weight=class_weights)
   ```

2. **é‡é‡‡æ ·**ï¼š
   ```python
   from torch.utils.data import WeightedRandomSampler
   
   # è®¡ç®—æ ·æœ¬æƒé‡
   class_counts = [5000, 1000]  # æ­£å¸¸:5000, å¼‚å¸¸:1000
   weights = [1.0/c for c in class_counts]
   sample_weights = [weights[label] for label in labels]
   
   sampler = WeightedRandomSampler(sample_weights, len(sample_weights))
   loader = DataLoader(dataset, sampler=sampler, ...)
   ```

3. **æ•°æ®å¢å¼º**ï¼š
   å¯¹å°‘æ•°ç±»åº”ç”¨æ›´å¼ºçš„å¢å¼º

---

## æœ€ä½³å®è·µ

### 1. æ•°æ®å‡†å¤‡

âœ… **æ¨èåšæ³•**ï¼š
- æŒ‰å—è¯•è€…ç»„ç»‡æ•°æ®ï¼Œé¿å…æ•°æ®æ³„éœ²
- é¢„å¤„ç†å‰æ£€æŸ¥éŸ³é¢‘è´¨é‡
- ä½¿ç”¨ä¸€è‡´çš„é‡‡æ ·ç‡
- ä¿ç•™åŸå§‹æ•°æ®å¤‡ä»½

âŒ **é¿å…**ï¼š
- æ··åˆä¸åŒæ¥æºçš„æ•°æ®è€Œä¸æ ‡æ³¨
- å¿½ç•¥éŸ³é¢‘è´¨é‡è¯„ä¼°
- åˆ é™¤åŸå§‹æ•°æ®

### 2. é¢„è®­ç»ƒ

âœ… **æ¨èåšæ³•**ï¼š
- ä½¿ç”¨å¤§æ‰¹æ¬¡ï¼ˆ64-128ï¼‰å’Œæ··åˆç²¾åº¦
- è®¾ç½®éªŒè¯é›†ç›‘æ§è®­ç»ƒ
- å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
- ä½¿ç”¨ TensorBoard/W&B ç›‘æ§
- è®¾ç½®éšæœºç§å­ä¿è¯å¯å¤ç°

âŒ **é¿å…**ï¼š
- è¿‡æ—©åœæ­¢è®­ç»ƒï¼ˆè‡³å°‘ 50 epochsï¼‰
- å¿½ç•¥éªŒè¯é›†æ€§èƒ½
- ä¸ä¿å­˜é…ç½®æ–‡ä»¶

### 3. å¾®è°ƒ

âœ… **æ¨èåšæ³•**ï¼š
- å…ˆå°è¯•çº¿æ€§è¯„ä¼°ï¼Œå†å…¨é‡å¾®è°ƒ
- ä½¿ç”¨è¾ƒå°çš„ç¼–ç å™¨å­¦ä¹ ç‡
- è®¾ç½®æ—©åœé¿å…è¿‡æ‹Ÿåˆ
- åœ¨å¤šä¸ªéšæœºç§å­ä¸‹è¯„ä¼°

âŒ **é¿å…**ï¼š
- ä½¿ç”¨è¿‡å¤§çš„å­¦ä¹ ç‡ï¼ˆå¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼‰
- åœ¨è®­ç»ƒé›†ä¸Šè¿‡æ‹Ÿåˆ
- åªåœ¨å•æ¬¡è¿è¡Œä¸‹æŠ¥å‘Šç»“æœ

### 4. è¯„ä¼°

âœ… **æ¨èåšæ³•**ï¼š
- ä½¿ç”¨å¤šç§æŒ‡æ ‡ï¼ˆAccuracy, AUROC, F1ï¼‰
- æŠ¥å‘Šç½®ä¿¡åŒºé—´ï¼ˆå¤šæ¬¡è¿è¡Œï¼‰
- ç»˜åˆ¶æ··æ·†çŸ©é˜µå’Œ ROC æ›²çº¿
- è¿›è¡Œè·¨æ•°æ®é›†è¯„ä¼°

âŒ **é¿å…**ï¼š
- åªæŠ¥å‘Šå‡†ç¡®ç‡
- åœ¨éªŒè¯é›†ä¸Šè°ƒå‚ååœ¨æµ‹è¯•é›†æŠ¥å‘Š
- å¿½ç•¥ç±»åˆ«ä¸å¹³è¡¡çš„å½±å“

### 5. å®éªŒç®¡ç†

âœ… **æ¨èåšæ³•**ï¼š
- ä½¿ç”¨æœ‰æ„ä¹‰çš„å®éªŒåç§°
- ç‰ˆæœ¬æ§åˆ¶é…ç½®æ–‡ä»¶
- è®°å½•æ¯æ¬¡å®éªŒçš„è¶…å‚æ•°
- ä½¿ç”¨å®éªŒè·Ÿè¸ªå·¥å…·ï¼ˆW&Bï¼‰

âŒ **é¿å…**ï¼š
- è¦†ç›–ä¹‹å‰çš„å®éªŒç»“æœ
- ä¸è®°å½•éšæœºç§å­
- æ‰‹åŠ¨ç®¡ç†å®éªŒ

### 6. ä»£ç å¼€å‘

âœ… **æ¨èåšæ³•**ï¼š
- è¿è¡Œå•å…ƒæµ‹è¯•
- ä½¿ç”¨ä»£ç æ ¼å¼åŒ–å·¥å…·ï¼ˆblack, isortï¼‰
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²

âŒ **é¿å…**ï¼š
- ç›´æ¥ä¿®æ”¹æ ¸å¿ƒä»£ç è€Œä¸æµ‹è¯•
- å¿½ç•¥ä»£ç é£æ ¼
- æäº¤æœªæµ‹è¯•çš„ä»£ç 

---

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ•°æ®å¢å¼º

åˆ›å»ºæ–°çš„å¢å¼ºå˜æ¢ï¼š

```python
# src/data/transforms.py

class MyCustomTransform(Transform):
    def __init__(self, param1, param2, p=0.5):
        super().__init__(p=p)
        self.param1 = param1
        self.param2 = param2
    
    def apply(self, signal_data, sample_rate):
        # å®ç°æ‚¨çš„å¢å¼ºé€»è¾‘
        augmented = ...
        return augmented

# ä½¿ç”¨
from src.data.transforms import Compose, MyCustomTransform

transforms = Compose([
    MyCustomTransform(param1=..., param2=...),
    # ... å…¶ä»–å˜æ¢
])
```

### è‡ªå®šä¹‰ç¼–ç å™¨

å®ç°æ–°çš„ç¼–ç å™¨æ¶æ„ï¼š

```python
# src/models/encoder.py

class MyCustomEncoder(nn.Module):
    def __init__(self, **kwargs):
        super().__init__()
        # å®šä¹‰æ‚¨çš„ç½‘ç»œå±‚
        
    def forward(self, x):
        # å‰å‘ä¼ æ’­
        return features
    
    def get_substructure_features(self, x):
        # è¿”å›ä¸­é—´ç‰¹å¾ï¼ˆç”¨äºå­ç»“æ„å¯¹æ¯”ï¼‰
        return mid_features

# æ³¨å†Œç¼–ç å™¨
def build_encoder(encoder_type, **kwargs):
    if encoder_type == "my_custom":
        return MyCustomEncoder(**kwargs)
    # ...
```

### è‡ªå®šä¹‰æŸå¤±å‡½æ•°

```python
# src/losses/contrastive.py

class MyCustomLoss(nn.Module):
    def __init__(self, **kwargs):
        super().__init__()
        # åˆå§‹åŒ–å‚æ•°
    
    def forward(self, z1, z2):
        # è®¡ç®—æŸå¤±
        loss = ...
        return loss
```

### å¯¼å‡ºæ¨¡å‹ç”¨äºéƒ¨ç½²

```python
# å¯¼å‡ºä¸º ONNX æ ¼å¼
import torch
from src.models.pahcl import PAHCLModel

model = PAHCLModel(...)
model.load_state_dict(torch.load('best_model.pt'))
model.eval()

dummy_input = torch.randn(1, 1, 4000)
torch.onnx.export(
    model,
    dummy_input,
    "pahcl_model.onnx",
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
)
```

### ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†

```python
import torch
import numpy as np
from src.models.pahcl import PAHCLModel
from src.data.preprocessing import load_audio, bandpass_filter

# åŠ è½½æ¨¡å‹
model = PAHCLModel(...)
checkpoint = torch.load('outputs/my_pretrain/best_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# åŠ è½½éŸ³é¢‘
audio, sr = load_audio('test_audio.wav', target_sr=5000)
audio = bandpass_filter(audio, sr, low=25, high=400)

# æ¨ç†
with torch.no_grad():
    audio_tensor = torch.from_numpy(audio).unsqueeze(0).unsqueeze(0).float()
    output = model(audio_tensor)
    features = output['features']
    
print(f"Extracted features shape: {features.shape}")
```

---

## é™„å½•

### A. å®Œæ•´å‘½ä»¤é€ŸæŸ¥è¡¨

```bash
# ç¯å¢ƒè®¾ç½®
conda create -n pahcl python=3.10
conda activate pahcl
pip install torch==2.1.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
pip install -e .

# æ•°æ®é¢„å¤„ç†
python scripts/preprocess.py --config configs/default.yaml

# é¢„è®­ç»ƒ
python scripts/pretrain.py --config configs/pretrain.yaml
torchrun --nproc_per_node=4 scripts/pretrain.py --config configs/pretrain.yaml --distributed

# å¾®è°ƒ
python scripts/finetune.py --config configs/finetune.yaml --pretrained outputs/pretrain/best_model.pt --linear-eval
python scripts/finetune.py --config configs/finetune.yaml --pretrained outputs/pretrain/best_model.pt
python scripts/finetune.py --config configs/finetune.yaml --pretrained outputs/pretrain/best_model.pt --few-shot --shot-ratio 0.1

# è¯„ä¼°
python scripts/evaluate.py --checkpoint outputs/finetune/best_model.pt --data-csv data/test.csv

# æ¶ˆèå®éªŒ
python scripts/ablation.py --config configs/ablation.yaml --all

# æµ‹è¯•
pytest tests/ -v
pytest tests/ --cov=src --cov-report=html
```

### B. é…ç½®å‚æ•°å®Œæ•´åˆ—è¡¨

è¯¦è§ `configs/default.yaml` æ–‡ä»¶ã€‚

### C. æ€§èƒ½åŸºå‡†

**ç¡¬ä»¶ç¯å¢ƒ**ï¼š
- GPU: NVIDIA A100 40GB
- CPU: 32 cores
- RAM: 128GB

**æ€§èƒ½æ•°æ®**ï¼š

| æ“ä½œ | æ—¶é—´ | ååé‡ |
|------|------|--------|
| é¢„å¤„ç† (10k éŸ³é¢‘) | ~30 min | ~5.5 audio/sec |
| é¢„è®­ç»ƒ (100 epochs, 50k cycles) | ~4 hours | ~350 cycles/sec |
| å¾®è°ƒ (50 epochs) | ~30 min | - |
| æ¨ç† (å•æ ·æœ¬) | ~10 ms | ~100 samples/sec |

### D. æ•…éšœæ’æŸ¥æ¸…å•

é‡åˆ°é—®é¢˜æ—¶ï¼ŒæŒ‰æ­¤æ¸…å•æ£€æŸ¥ï¼š

- [ ] PyTorch å’Œ CUDA ç‰ˆæœ¬åŒ¹é…ï¼Ÿ
- [ ] æ•°æ®æ ¼å¼æ­£ç¡®ï¼Ÿ
- [ ] é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Ÿ
- [ ] GPU å†…å­˜è¶³å¤Ÿï¼Ÿ
- [ ] ä¾èµ–åŒ…ç‰ˆæœ¬æ­£ç¡®ï¼Ÿ
- [ ] éšæœºç§å­å·²è®¾ç½®ï¼Ÿ
- [ ] æ—¥å¿—æ–‡ä»¶ä¸­æœ‰é”™è¯¯ä¿¡æ¯ï¼Ÿ

---

## è”ç³»ä¸æ”¯æŒ

- **GitHub Issues**: https://github.com/dunkmonkey/PA-HCL/issues
- **æ–‡æ¡£**: https://github.com/dunkmonkey/PA-HCL/wiki
- **è®¨è®ºåŒº**: https://github.com/dunkmonkey/PA-HCL/discussions

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**æœ€åæ›´æ–°**ï¼š2026å¹´1æœˆ18æ—¥
