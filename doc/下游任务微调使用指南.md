# PA-HCL ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒä½¿ç”¨æŒ‡å—

**ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-01-20

---

## ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)
2. [æ•°æ®å‡†å¤‡](#2-æ•°æ®å‡†å¤‡)
3. [å¾®è°ƒè®­ç»ƒ](#3-å¾®è°ƒè®­ç»ƒ)
4. [è¯„ä¼°ä¸æµ‹è¯•](#4-è¯„ä¼°ä¸æµ‹è¯•)
5. [é«˜çº§ç”¨æ³•](#5-é«˜çº§ç”¨æ³•)
6. [å¸¸è§é—®é¢˜](#6-å¸¸è§é—®é¢˜)
7. [é…ç½®å‚è€ƒ](#7-é…ç½®å‚è€ƒ)

---

## 1. å¿«é€Ÿå¼€å§‹

### 1.1 ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/dunkmonkey/PA-HCL.git
cd PA-HCL

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n pahcl python=3.10
conda activate pahcl

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install -e .
```

### 1.2 ä¸€é”®è¿è¡Œï¼ˆæ¨èï¼‰

```bash
# å®Œæ•´æµç¨‹ï¼šå‡†å¤‡æ•°æ® -> è®­ç»ƒæ‰€æœ‰ä»»åŠ¡ -> æ±‡æ€»ç»“æœ
./scripts/run_downstream.sh all
```

### 1.3 å•ä»»åŠ¡å¿«é€Ÿè®­ç»ƒ

```bash
# å‡è®¾å·²æœ‰é¢„è®­ç»ƒæ¨¡å‹å’Œå‡†å¤‡å¥½çš„æ•°æ®
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt
```

---

## 2. æ•°æ®å‡†å¤‡

### 2.1 æ•°æ®é›†ä¸‹è½½

#### CirCor DigiScope 2022

```bash
# è‡ªåŠ¨ä¸‹è½½
python scripts/data_preparation/download_datasets.py --dataset circor

# æˆ–æ‰‹åŠ¨ä¸‹è½½
# è®¿é—®: https://physionet.org/content/circor-heart-sound/
# ä¸‹è½½å¹¶è§£å‹åˆ°: /root/autodl-tmp/data/raw/circor/
```

#### PhysioNet 2016

```bash
python scripts/data_preparation/download_datasets.py --dataset physionet2016
```

#### PASCAL Challenge

éœ€æ‰‹åŠ¨ä¸‹è½½:
1. è®¿é—® https://istethoscope.peterjbentley.com/heartchallenge/
2. ä¸‹è½½æ•°æ®é›†
3. è§£å‹åˆ° `/root/autodl-tmp/data/raw/pascal/`

### 2.2 é¢„å¤„ç†ï¼ˆæå–å¿ƒåŠ¨å‘¨æœŸï¼‰

```bash
# é¢„å¤„ç†æ‰€æœ‰æ•°æ®é›†
python scripts/preprocess.py \
    --raw_dir /root/autodl-tmp/data/raw \
    --output_dir /root/autodl-tmp/data/processed \
    --num_workers 8
```

**é¢„å¤„ç†è¾“å‡ºç»“æ„**ï¼š
```
/root/autodl-tmp/data/processed/
â”œâ”€â”€ subject_10001/
â”‚   â”œâ”€â”€ rec_AV/
â”‚   â”‚   â”œâ”€â”€ cycle_000.npy
â”‚   â”‚   â”œâ”€â”€ cycle_001.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ rec_MV/
â”‚   â”œâ”€â”€ rec_PV/
â”‚   â””â”€â”€ rec_TV/
â”œâ”€â”€ subject_10002/
â”‚   â””â”€â”€ ...
â””â”€â”€ processing_stats.json
```

### 2.3 ä¸‹æ¸¸ä»»åŠ¡æ•°æ®å‡†å¤‡

#### å‡†å¤‡æ‰€æœ‰ä»»åŠ¡

```bash
python scripts/data_preparation/prepare_downstream_tasks.py \
    --dataset all \
    --raw-dir /root/autodl-tmp/data/raw \
    --processed-dir /root/autodl-tmp/data/processed \
    --output-dir /root/autodl-tmp/data/downstream \
    --seed 42 \
    --verbose
```

#### å‡†å¤‡ç‰¹å®šæ•°æ®é›†

```bash
# ä»…å‡†å¤‡ CirCor æ•°æ®é›†ï¼ˆåŒ…å« murmur å’Œ outcome ä¸¤ä¸ªä»»åŠ¡ï¼‰
python scripts/data_preparation/prepare_downstream_tasks.py --dataset circor

# ä»…å‡†å¤‡ PhysioNet 2016
python scripts/data_preparation/prepare_downstream_tasks.py --dataset physionet2016

# ä»…å‡†å¤‡ PASCAL
python scripts/data_preparation/prepare_downstream_tasks.py --dataset pascal
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | æè¿° |
|------|-------|------|
| `--dataset` | `all` | æ•°æ®é›†åç§°ï¼š`circor`, `physionet2016`, `pascal`, `all` |
| `--raw-dir` | `data/raw` | åŸå§‹æ•°æ®ç›®å½• |
| `--processed-dir` | `data/processed` | é¢„å¤„ç†æ•°æ®ç›®å½• |
| `--output-dir` | `data/downstream` | è¾“å‡ºç›®å½• |
| `--seed` | `42` | éšæœºç§å­ï¼ˆå½±å“æ•°æ®åˆ’åˆ†ï¼‰ |
| `--copy` | `False` | ä½¿ç”¨æ–‡ä»¶å¤åˆ¶è€Œéç¡¬é“¾æ¥ |
| `--verbose` | `False` | æ˜¾ç¤ºè¯¦ç»†æ—¥å¿— |

**è¾“å‡ºç»“æ„**ï¼š
```
/root/autodl-tmp/data/downstream/
â”œâ”€â”€ circor_murmur/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ subject_10001/rec_AV/cycle_000.npy
â”‚   â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ train.csv          # åŒ…å«ç±»åˆ«æƒé‡
â”‚   â”œâ”€â”€ val.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ task_config.json   # ä»»åŠ¡é…ç½®
â”œâ”€â”€ circor_outcome/
â”œâ”€â”€ physionet2016/
â””â”€â”€ pascal/
```

---

## 3. å¾®è°ƒè®­ç»ƒ

### 3.1 åŸºæœ¬ç”¨æ³•

```bash
# ä½¿ç”¨ä»»åŠ¡åç§°è®­ç»ƒï¼ˆæ¨èï¼‰
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --output-dir outputs \
    --experiment-name my_experiment
```

#### ğŸ†• MoCo/SimCLR æ£€æŸ¥ç‚¹å…¼å®¹æ€§

**è‡ªåŠ¨å…¼å®¹**ï¼šç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«é¢„è®­ç»ƒæ¨¡å¼ï¼ˆSimCLR æˆ– MoCoï¼‰ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®

- âœ… **SimCLR é¢„è®­ç»ƒæƒé‡** - ç›´æ¥åŠ è½½æ‰€æœ‰å‚æ•°
- âœ… **MoCo é¢„è®­ç»ƒæƒé‡** - è‡ªåŠ¨è¿‡æ»¤åŠ¨é‡ç¼–ç å™¨å’Œé˜Ÿåˆ—å‚æ•°

```bash
# ä¸¤ç§é¢„è®­ç»ƒæ¨¡å¼çš„æ£€æŸ¥ç‚¹å‡å¯ç›´æ¥ä½¿ç”¨
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/moco_best.pt  # æˆ– simclr_best.pt
```

**æ—¥å¿—è¾“å‡ºç¤ºä¾‹ï¼ˆMoCo æ£€æŸ¥ç‚¹ï¼‰**ï¼š
```
åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: checkpoints/moco_best.pt
ä»æ£€æŸ¥ç‚¹å…ƒæ•°æ®æ£€æµ‹åˆ° MoCo: True
  åŠ¨é‡ç³»æ•°: 0.999
  é˜Ÿåˆ—å¤§å°: 8192
ä¸‹æ¸¸ä»»åŠ¡ä¸éœ€è¦ MoCo åŠ¨é‡ç¼–ç å™¨ï¼Œå·²è‡ªåŠ¨ç¦ç”¨
å·²è·³è¿‡ 234 ä¸ª MoCo ç›¸å…³å‚æ•°
æˆåŠŸåŠ è½½ 512 ä¸ªä¸»æ¨¡å‹å‚æ•°
```

> ğŸ’¡ æŠ€æœ¯ç»†èŠ‚è§ [MoCoä¼˜åŒ–å®ç°è¯´æ˜.md](./MoCoä¼˜åŒ–å®ç°è¯´æ˜.md#ä¸‹æ¸¸å¾®è°ƒå…¼å®¹æ€§)

### 3.2 è®­ç»ƒæ¨¡å¼

#### å…¨é‡å¾®è°ƒï¼ˆé»˜è®¤ï¼‰

ç¼–ç å™¨å’Œåˆ†ç±»å™¨éƒ½å‚ä¸è®­ç»ƒï¼š

```bash
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt
```

#### çº¿æ€§è¯„ä¼°

å†»ç»“ç¼–ç å™¨ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´ï¼š

```bash
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --linear-eval
```

#### å°‘æ ·æœ¬å­¦ä¹ 

ä½¿ç”¨éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼š

```bash
# ä½¿ç”¨ 10% è®­ç»ƒæ•°æ®
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --few-shot --shot-ratio 0.1

# ä½¿ç”¨ 1% è®­ç»ƒæ•°æ®
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --few-shot --shot-ratio 0.01
```

### 3.3 å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | æè¿° |
|------|-------|------|
| `--task` | æ—  | ä»»åŠ¡åç§°ï¼ˆå¿…éœ€æˆ–ä½¿ç”¨ --configï¼‰ |
| `--config` | `configs/finetune.yaml` | é…ç½®æ–‡ä»¶è·¯å¾„ |
| `--pretrained` | æ—  | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰ |
| `--data-dir` | `data/downstream` | ä¸‹æ¸¸æ•°æ®ç›®å½• |
| `--output-dir` | `outputs` | è¾“å‡ºç›®å½• |
| `--experiment-name` | `downstream` | å®éªŒåç§° |
| `--linear-eval` | `False` | çº¿æ€§è¯„ä¼°æ¨¡å¼ |
| `--few-shot` | `False` | å°‘æ ·æœ¬å­¦ä¹ æ¨¡å¼ |
| `--shot-ratio` | `0.1` | å°‘æ ·æœ¬æ¯”ä¾‹ |
| `--epochs` | é…ç½®æ–‡ä»¶ | è®­ç»ƒè½®æ•° |
| `--lr` | é…ç½®æ–‡ä»¶ | å­¦ä¹ ç‡ |
| `--batch-size` | é…ç½®æ–‡ä»¶ | æ‰¹æ¬¡å¤§å° |
| `--seed` | `42` | éšæœºç§å­ |

### 3.4 è®­ç»ƒæ‰€æœ‰ä»»åŠ¡

#### ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬

```bash
# è®­ç»ƒæ‰€æœ‰ä»»åŠ¡ï¼ˆå…¨é‡å¾®è°ƒï¼‰
./scripts/run_downstream.sh train-all

# è®­ç»ƒæ‰€æœ‰ä»»åŠ¡ï¼ˆçº¿æ€§è¯„ä¼°ï¼‰
./scripts/run_downstream.sh train-all linear
```

#### æ‰‹åŠ¨è®­ç»ƒ

```bash
# CirCor æ‚éŸ³æ£€æµ‹
python scripts/finetune.py --task circor_murmur --pretrained ...

# CirCor ä¸´åºŠç»“æœ
python scripts/finetune.py --task circor_outcome --pretrained ...

# PhysioNet 2016
python scripts/finetune.py --task physionet2016 --pretrained ...

# PASCAL
python scripts/finetune.py --task pascal --pretrained ...
```

### 3.5 å¤š GPU è®­ç»ƒ

```bash
# ä½¿ç”¨ 4 ä¸ª GPU
torchrun --nproc_per_node=4 scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --batch-size 64
```

### 3.6 è®­ç»ƒè¾“å‡º

```
outputs/circor_murmur_my_experiment/
â”œâ”€â”€ config.yaml              # ä¿å­˜çš„é…ç½®
â”œâ”€â”€ train.log                # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ events.out.tfevents.*    # TensorBoard æ—¥å¿—
â”œâ”€â”€ epoch_10.pt              # å‘¨æœŸæ£€æŸ¥ç‚¹
â”œâ”€â”€ epoch_20.pt
â”œâ”€â”€ best_model.pt            # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ final_model.pt           # æœ€ç»ˆæ¨¡å‹
â””â”€â”€ final_metrics.json       # æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡
```

---

## 4. è¯„ä¼°ä¸æµ‹è¯•

### 4.1 è®­ç»ƒåè‡ªåŠ¨è¯„ä¼°

è®­ç»ƒç»“æŸåä¼šè‡ªåŠ¨åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼Œç»“æœä¿å­˜åœ¨ `final_metrics.json`ï¼š

```json
{
    "test_accuracy": 0.8523,
    "test_f1": 0.8156,
    "test_f1_macro": 0.7892,
    "test_auroc": 0.9234,
    "test_precision": 0.8345,
    "test_recall": 0.7978
}
```

### 4.2 æ‰‹åŠ¨è¯„ä¼°

```bash
python scripts/evaluate.py \
    --checkpoint outputs/circor_murmur_exp1/best_model.pt \
    --task circor_murmur \
    --data-dir data/downstream \
    --split test
```

### 4.3 æŸ¥çœ‹ TensorBoard

```bash
tensorboard --logdir outputs/circor_murmur_exp1
```

### 4.4 æ±‡æ€»æ‰€æœ‰å®éªŒç»“æœ

```bash
./scripts/run_downstream.sh summarize
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
å®éªŒç»“æœæ±‡æ€»
============================================================
ä»»åŠ¡                 å®éªŒ                           Accuracy     F1           AUROC
------------------------------------------------------------
circor_murmur        circor_murmur_exp1            0.8523       0.8156       0.9234
circor_outcome       circor_outcome_exp1           0.8912       0.8745       0.9456
physionet2016        physionet2016_exp1            0.8234       0.7989       0.8876
pascal               pascal_exp1                   0.7856       0.7523       0.8567
============================================================
```

---

## 5. å®éªŒç›‘æ§

### 5.1 ç›‘æ§æ–¹å¼

PA-HCL æ”¯æŒä¸¤ç§å®éªŒç›‘æ§æ–¹å¼ï¼š

- **TensorBoard**ï¼šæœ¬åœ°è½»é‡çº§ç›‘æ§ï¼Œé€‚åˆå¿«é€Ÿè°ƒè¯•
- **WandB**ï¼šäº‘ç«¯ç›‘æ§ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œæ”¯æŒå›¢é˜Ÿåä½œ

### 5.2 ä½¿ç”¨ TensorBoard

#### å¯ç”¨ TensorBoard

```bash
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --tensorboard
```

#### æŸ¥çœ‹ç»“æœ

åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨ TensorBoardï¼š

```bash
# æŸ¥çœ‹å•ä¸ªå®éªŒ
tensorboard --logdir outputs/circor_murmur_finetune/tensorboard

# æŸ¥çœ‹æ‰€æœ‰å®éªŒï¼ˆå¯¹æ¯”ï¼‰
tensorboard --logdir outputs

# æŒ‡å®šç«¯å£
tensorboard --logdir outputs --port 6006
```

åœ¨æµè§ˆå™¨æ‰“å¼€ï¼š`http://localhost:6006`

#### TensorBoard è®°å½•å†…å®¹

- **è®­ç»ƒæŒ‡æ ‡**ï¼šloss, accuracy, f1, precision, recall
- **éªŒè¯æŒ‡æ ‡**ï¼šloss, accuracy, f1, auroc, auprc
- **å­¦ä¹ ç‡**ï¼šç¼–ç å™¨å’Œåˆ†ç±»å™¨å­¦ä¹ ç‡å˜åŒ–

### 5.3 ä½¿ç”¨ WandB

#### é¦–æ¬¡è®¾ç½®

```bash
# å®‰è£…
pip install wandb

# ç™»å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
wandb login
```

è®¿é—® https://wandb.ai/authorize è·å– API Keyã€‚

#### å¯ç”¨ WandB

```bash
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --wandb \
    --wandb-project PA-HCL-Downstream
```

#### WandB é¢å¤–åŠŸèƒ½

é™¤äº†æ‰€æœ‰ TensorBoard æŒ‡æ ‡å¤–ï¼ŒWandB è¿˜è®°å½•ï¼š
- GPU/å†…å­˜/CPU ä½¿ç”¨ç‡
- æ¨¡å‹æ¢¯åº¦å’Œå‚æ•°åˆ†å¸ƒ
- å®Œæ•´é…ç½®ä¿¡æ¯
- è‡ªåŠ¨ç”Ÿæˆå®éªŒæŠ¥å‘Š

### 5.4 åŒæ—¶ä½¿ç”¨ä¸¤è€…

```bash
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --tensorboard \
    --wandb
```

**æ¨èç­–ç•¥**ï¼š
- æœ¬åœ°è°ƒè¯•ï¼š`--tensorboard`
- æ­£å¼å®éªŒï¼š`--wandb`
- é‡è¦å®éªŒï¼šåŒæ—¶ä½¿ç”¨ä¸¤è€…

### 5.5 ç›‘æ§å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | æè¿° |
|------|-------|------|
| `--tensorboard` | `False` | å¯ç”¨ TensorBoard |
| `--wandb` | `False` | å¯ç”¨ WandB |
| `--wandb-project` | `PA-HCL` | WandB é¡¹ç›®åç§° |
| `--wandb-entity` | `None` | WandB ç”¨æˆ·/å›¢é˜Ÿå |

### 5.6 ç›‘æ§ç¤ºä¾‹

```bash
# çº¿æ€§è¯„ä¼° + TensorBoard
python scripts/finetune.py \
    --task circor_murmur \
    --pretrained checkpoints/pretrain/best_model.pt \
    --linear-eval \
    --tensorboard

# å°‘æ ·æœ¬å­¦ä¹  + WandB
python scripts/finetune.py \
    --task physionet2016 \
    --pretrained checkpoints/pretrain/best_model.pt \
    --few-shot --shot-ratio 0.1 \
    --wandb --wandb-project PA-HCL-FewShot

# æ‰¹é‡å®éªŒç›‘æ§
for task in circor_murmur circor_outcome physionet2016 pascal; do
    python scripts/finetune.py \
        --task $task \
        --pretrained checkpoints/pretrain/best_model.pt \
        --tensorboard --wandb \
        --wandb-project PA-HCL-AllTasks
done
```

### 5.7 å¸¸è§é—®é¢˜

**Q: TensorBoard ç«¯å£è¢«å ç”¨**
```bash
tensorboard --logdir outputs --port 6007
```

**Q: WandB ç¦»çº¿æ¨¡å¼**
```bash
export WANDB_MODE=offline
python scripts/finetune.py --task ... --wandb
```

**Q: åœ¨å®¹å™¨ä¸­è®¿é—® TensorBoard**
```bash
tensorboard --logdir outputs --host 0.0.0.0 --port 6006
```

---

## 6. é«˜çº§ç”¨æ³•

### 6.1 è‡ªå®šä¹‰é…ç½®

åˆ›å»ºè‡ªå®šä¹‰é…ç½®æ–‡ä»¶ï¼š

```yaml
# configs/my_config.yaml
task:
  name: "circor_murmur"
  type: "classification"

downstream:
  num_classes: 3
  num_epochs: 100
  batch_size: 64
  learning_rate: 5e-4
  weight_decay: 1e-4
  use_class_weights: true
  label_smoothing: 0.1

training:
  use_amp: true
  early_stopping_patience: 20

evaluation:
  primary_metric: "f1_macro"
```

ä½¿ç”¨è‡ªå®šä¹‰é…ç½®ï¼š

```bash
python scripts/finetune.py \
    --config configs/my_config.yaml \
    --pretrained checkpoints/pretrain/best_model.pt
```

### 6.2 è¶…å‚æ•°æœç´¢

```bash
# å­¦ä¹ ç‡æœç´¢ï¼ˆç»“åˆ WandB ç›‘æ§ï¼‰
for lr in 1e-3 5e-4 1e-4 5e-5; do
    python scripts/finetune.py \
        --task circor_murmur \
        --pretrained checkpoints/pretrain/best_model.pt \
        --lr $lr \
        --experiment-name "lr_${lr}" \
        --wandb --wandb-project PA-HCL-HPSearch
done
```

### 6.3 è·¨æ•°æ®é›†è¯„ä¼°

åœ¨ä¸€ä¸ªæ•°æ®é›†ä¸Šå¾®è°ƒï¼Œåœ¨å¦ä¸€ä¸ªæ•°æ®é›†ä¸Šè¯„ä¼°ï¼š

```bash
# åœ¨ CirCor ä¸Šå¾®è°ƒ
python scripts/finetune.py \
    --task circor_outcome \
    --pretrained checkpoints/pretrain/best_model.pt \
    --experiment-name circor_trained

# åœ¨ PhysioNet 2016 ä¸Šè¯„ä¼°ï¼ˆéœ€è¦æ ‡ç­¾æ˜ å°„ä¸€è‡´ï¼‰
python scripts/evaluate.py \
    --checkpoint outputs/circor_outcome_circor_trained/best_model.pt \
    --task physionet2016 \
    --data-dir /root/autodl-tmp/data/downstream
```
6.4 é›†æˆå­¦ä¹ 

```bash
# è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼ˆä½¿ç”¨ WandB åˆ†ç»„ï¼‰
for seed in 42 123 456; do
    python scripts/finetune.py \
        --task circor_murmur \
        --pretrained checkpoints/pretrain/best_model.pt \
        --seed $seed \
        --experiment-name "ensemble_seed_${seed}" \
        --wandb --wandb-project PA-HCL-Ensemble
done

# é›†æˆé¢„æµ‹ï¼ˆéœ€è‡ªè¡Œå®ç°ï¼‰
python scripts/ensemble.py \
    --checkpoints outputs/circor_murmur_ensemble_*/best_model.pt \
    --task circor_murmur
```

---

## 7. å¸¸è§é—®é¢˜

### 7
### 6.1 æ•°æ®å‡†å¤‡é—®é¢˜

**Q: æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶**

```
WARNING: æœªæ‰¾åˆ°ä»»ä½•æ ‡ç­¾ï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
```

**A**: ç¡®ä¿åŸå§‹æ•°æ®ç›®å½•ç»“æ„æ­£ç¡®ï¼š
- CirCor: `/root/autodl-tmp/data/raw/circor/training_data/` å’Œ `/root/autodl-tmp/data/raw/circor/training_data.csv`
- PhysioNet 2016: `/root/autodl-tmp/data/raw/physionet2016/training-*/` å’Œ `REFERENCE.csv`

**Q: é¢„å¤„ç†åæ²¡æœ‰å‘¨æœŸæ–‡ä»¶**

**A**: æ£€æŸ¥åŸå§‹éŸ³é¢‘æ–‡ä»¶è´¨é‡ï¼š
```bash
# æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
python -c "
import librosa
audio, sr = librosa.load('/root/autodl-tmp/data/raw/circor/training_data/10001_AV.wav')
print(f'Duration: {len(audio)/sr:.2f}s, SR: {sr}')
"
```
7
### 6.2 è®­ç»ƒé—®é¢˜

**Q: CUDA å†…å­˜ä¸è¶³**

**A**: å‡å°æ‰¹æ¬¡å¤§å°ï¼š
```bash
python scripts/finetune.py --task circor_murmur --batch-size 16
```

**Q: è®­ç»ƒä¸æ”¶æ•›**

**A**: å°è¯•ï¼š
1. é™ä½å­¦ä¹ ç‡ï¼š`--lr 1e-4`
2. å¢åŠ  warmupï¼šä¿®æ”¹é…ç½® `warmup_epochs: 10`
3. æ£€æŸ¥æ•°æ®åˆ†å¸ƒï¼šæŸ¥çœ‹ `train.csv` ä¸­çš„ç±»åˆ«æ¯”ä¾‹

**Q: ç±»åˆ«ä¸å¹³è¡¡å¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»**

**A**: ç¡®ä¿å¯ç”¨ç±»åˆ«æƒé‡ï¼š
```bash
# æ£€æŸ¥ CSV æ˜¯å¦åŒ…å«ç±»åˆ«æƒé‡
head -n 1 data/downstream/circor_murmur/train.csv
# åº”æ˜¾ç¤º: # class_weights: [...]
```

### 7.3 è¯„ä¼°é—®é¢˜

**Q: æµ‹è¯•æŒ‡æ ‡å¼‚å¸¸ä½**

**A**: æ£€æŸ¥ï¼š
1. è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¦æœ‰æ•°æ®æ³„éœ²
2. é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
3. æ ‡ç­¾æ˜ å°„æ˜¯å¦æ­£ç¡®

### 7.4 ç›‘æ§é—®é¢˜

**Q: WandB ç™»å½•å¤±è´¥**
```bash
wandb login --relogin
```

**Q: TensorBoard æ— æ³•å¯åŠ¨**
```bash
pip install tensorboard
```

**Q: åœ¨å®¹å™¨/è¿œç¨‹æœåŠ¡å™¨ä¸Šä½¿ç”¨ç›‘æ§**
```bash
# TensorBoardï¼šç»‘å®šåˆ°æ‰€æœ‰æ¥å£
tensorboard --logdir outputs --host 0.0.0.0 --port 6006

# WandBï¼šç¦»çº¿æ¨¡å¼
export WANDB_MODE=offline
```

---

## 8. é…ç½®å‚è€ƒ

### 8.1 å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
# configs/finetune.yaml

experiment:
  name: "pahcl_finetune"
  description: "PA-HCL ä¸‹æ¸¸å¾®è°ƒ"

task:
  name: "default"
  type: "classification"

data:
  base_dir: "data/downstream"
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  sample_rate: 5000
  target_length: 4000
  num_substructures: 4

model:
  encoder_type: "cnn_mamba"
  cnn_channels: [32, 64, 128, 256]
  cnn_kernel_sizes: [7, 5, 5, 3]
  cnn_strides: [2, 2, 2, 2]
  mamba_d_model: 256
  mamba_n_layers: 4

classifier:
  hidden_dim: 128
  dropout: 0.3

downstream:
  num_classes: 2
  label_map:
    normal: 0
    abnormal: 1
  hidden_dim: 128
  dropout: 0.3
  num_epochs: 100
  batch_size: 32
  learning_rate: 1e-3
  weight_decay: 1e-4
  warmup_epochs: 5
  early_stopping_patience: 15
  label_smoothing: 0.1
  use_class_weights: true

training:
  num_epochs: 100
  batch_size: 32
  learning_rate: 1e-3
  weight_decay: 1e-4
  warmup_epochs: 5
  min_lr: 1e-7
  encoder_lr_scale: 0.1
  label_smoothing: 0.1
  use_class_weights: true
  early_stopping_patience: 15
  grad_clip_norm: 1.0
  num_workers: 4
  use_amp: true
  log_interval: 20
  sa8e_interval: 10

pretrain:
  checkpoint_path: "checkpoints/pretrain/best_model.pt"
  load_encoder_only: true
  freeze_encoder: false

evaluation:
  primary_metric: "f1_macro"
  metrics:
    - accuracy
    - f1
    - f1_macro
    - auroc
    - precision
    - recall
  save_confusion_matrix: true

seed: 42
```

### 7.2 ä»»åŠ¡ç‰¹å®šé…ç½®

#### circor_murmur.yaml

```yaml
task:
  name: "circor_murmur"
  type: "classification"

downstream:
  num_classes: 3
  label_map:
    Present: 0
    Absent: 1
    Unknown: 2

evaluation:
  primary_metric: "f1_macro"
```

#### circor_outcome.yaml

```yaml
task:
  name: "circor_outcome"
  type: "classification"

downstream:
  num_classes: 2
  label_map:
    Normal: 0
    Abnormal: 1

evaluation:
  primary_metric: "auroc"
```

---

## é™„å½•

### A. æ”¯æŒçš„è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| `accuracy` | å‡†ç¡®ç‡ | å¹³è¡¡æ•°æ®é›† |
| `f1` | F1 åˆ†æ•°ï¼ˆäºŒåˆ†ç±»ï¼‰ | äºŒåˆ†ç±» |
| `f1_macro` | å®å¹³å‡ F1 | å¤šåˆ†ç±»ã€ä¸å¹³è¡¡æ•°æ® |
| `f1_weighted` | åŠ æƒ F1 | å¤šåˆ†ç±» |
| `auroc` | ROC æ›²çº¿ä¸‹é¢ç§¯ | äºŒåˆ†ç±» |
| `auprc` | PR æ›²çº¿ä¸‹é¢ç§¯ | é«˜åº¦ä¸å¹³è¡¡æ•°æ® |
| `precision` | ç²¾ç¡®ç‡ | å…³æ³¨å‡é˜³æ€§ |
| `recall` | å¬å›ç‡ | å…³æ³¨å‡é˜´æ€§ |
| `specificity` | ç‰¹å¼‚æ€§ | åŒ»å­¦è¯Šæ–­ |

### B. æ•°æ®é›†ç»Ÿè®¡

| æ•°æ®é›† | å—è¯•è€…æ•° | å½•éŸ³æ•° | å‘¨æœŸæ•°ï¼ˆçº¦ï¼‰ | ç±»åˆ« |
|--------|---------|-------|-------------|------|
| CirCor 2022 | ~1000 | ~5000 | ~50000 | Murmur(3), Outcome(2) |
| PhysioNet 2016 | ~3000 | ~3000 | ~30000 | Normal/Abnormal |
| PASCAL | ~500 | ~1000 | ~10000 | Normal/Murmur/Extrasystole |

---

**æ–‡æ¡£ç»“æŸ**

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚
