# PA-HCL 预训练配置
# ==================================
# 使用分层对比学习的自监督预训练配置

# 实验信息
experiment:
  name: "pahcl_pretrain"
  description: "PCG 数据的 PA-HCL 自监督预训练"

# 数据设置
data:
  raw_dir: "/root/autodl-tmp/data/raw"
  processed_dir: "/root/autodl-tmp/data/processed"
  sample_rate: 5000
  segment_duration: 1.0  # 每个心动周期片段的秒数
  num_substructures: 4   # K (S1, 收缩期, S2, 舒张期)
  
  # 预处理
  bandpass_low: 25
  bandpass_high: 400
  min_cycle_duration: 0.4
  max_cycle_duration: 1.5
  min_snr: 5.0

# 模型架构
model:
  encoder_type: "cnn_mamba"  # "cnn_mamba", "cnn_transformer", "cnn_only"
  
  # CNN 主干网络
  cnn_channels: [32, 64, 128, 256]
  cnn_kernel_sizes: [7, 5, 5, 3]
  cnn_strides: [2, 2, 2, 2]  # 总下采样: 16x
  cnn_dropout: 0.1
  
  # Mamba 设置
  mamba_d_model: 256
  mamba_n_layers: 4
  mamba_d_state: 16
  mamba_expand: 2
  mamba_dropout: 0.1
  
  # 池化层
  pool_type: "mean"  # "mean", "max", "cls"
  
  # 投影头
  proj_hidden_dim: 512
  proj_output_dim: 128
  proj_num_layers: 2
  
  # 子结构投影
  sub_proj_hidden_dim: 256
  sub_proj_output_dim: 64
  
  # MoCo 设置 (Step 2 & 3)
  use_moco: false  # 是否启用 MoCo 风格动量编码器（仅周期级）
  moco_momentum: 0.999  # 动量系数（默认 0.999）
  queue_size: 8192  # Step 3: 周期级特征队列大小（约 256MB 显存）

# 损失函数
loss:
  temperature: 0.07
  lambda_cycle: 1.0
  lambda_sub: 1.0
  align_substructures: true

# 训练设置
training:
  # 基础设置
  num_epochs: 100
  batch_size: 64
  num_workers: 4
  pin_memory: true  # 加速数据传输
  prefetch_factor: 2  # 预取批次数量
  
  # 优化器 (Step 5: 根据有效batch size调整)
  # 有效 batch_size = 64 * 4 = 256
  # 学习率线性缩放: lr = base_lr * (effective_batch / base_batch)
  # base_lr = 1e-3 for batch_size=64, so for 256: lr = 1e-3 * (256/64) = 4e-3
  # 但考虑到稳定性，使用 2e-3 (保守的缩放因子 2x)
  learning_rate: 2e-3  # Step 5: 从 1e-3 提升到 2e-3
  weight_decay: 1e-4
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_eps: 1e-8
  
  # 调度器 (Step 5: 延长 warmup)
  warmup_epochs: 20  # Step 5: 从 10 延长到 20（因有效batch size增大）
  min_lr: 1e-6
  
  # 训练技巧 (Step 1优化)
  use_amp: true  # 启用混合精度训练
  gradient_accumulation_steps: 4  # 有效batch_size = 64 * 4 = 256
  grad_clip_norm: 1.0
  
  # 日志和保存
  log_interval: 50
  save_interval: 10

# 数据增强
augmentation:
  # 时域
  time_shift_max: 0.1
  amplitude_scale_range: [0.8, 1.2]
  gaussian_noise_std: 0.01
  time_stretch_range: [0.9, 1.1]
  
  # 频域
  time_mask_max_ratio: 0.006  # 30ms / 5000Hz 片段
  freq_mask_max_ratio: 0.15
  
  # 概率
  prob_time_shift: 0.5
  prob_amplitude_scale: 0.5
  prob_gaussian_noise: 0.5
  prob_time_stretch: 0.3
  prob_time_mask: 0.5
  prob_freq_mask: 0.3

# 分布式训练
distributed:
  backend: "nccl"
  find_unused_parameters: false

# 可复现性
seed: 42
